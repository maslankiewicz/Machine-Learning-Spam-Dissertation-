{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from yellowbrick.features.manifold import Manifold\n",
    "import yellowbrick as yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open(\"apple.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From: Apple Inc. - Izolda Jablonska <reply@unpogina.info>\\nSubject: Nice to meet you, Agnieszka\\nHello Agnieszka,\\nCongratulations to all of our recent winners of the Apple smartphone competition.\\nApple offered you a chance to win the latest iPhone - one of the most popular and best smartphones of the moment.\\nNo wonder that we have received thousands of applications, including yours! IPhone XS winner this week is ... Agnieszka Malankiewicz\\nCongratulations, Agnieszka,\\nReceive your iPhone XS!'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(data) #tokenising the email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['From',\n",
       " ':',\n",
       " 'Apple',\n",
       " 'Inc.',\n",
       " '-',\n",
       " 'Izolda',\n",
       " 'Jablonska',\n",
       " '<',\n",
       " 'reply',\n",
       " '@',\n",
       " 'unpogina.info',\n",
       " '>',\n",
       " 'Subject',\n",
       " ':',\n",
       " 'Nice',\n",
       " 'to',\n",
       " 'meet',\n",
       " 'you',\n",
       " ',',\n",
       " 'Agnieszka',\n",
       " 'Hello',\n",
       " 'Agnieszka',\n",
       " ',',\n",
       " 'Congratulations',\n",
       " 'to',\n",
       " 'all',\n",
       " 'of',\n",
       " 'our',\n",
       " 'recent',\n",
       " 'winners',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Apple',\n",
       " 'smartphone',\n",
       " 'competition',\n",
       " '.',\n",
       " 'Apple',\n",
       " 'offered',\n",
       " 'you',\n",
       " 'a',\n",
       " 'chance',\n",
       " 'to',\n",
       " 'win',\n",
       " 'the',\n",
       " 'latest',\n",
       " 'iPhone',\n",
       " '-',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'most',\n",
       " 'popular',\n",
       " 'and',\n",
       " 'best',\n",
       " 'smartphones',\n",
       " 'of',\n",
       " 'the',\n",
       " 'moment',\n",
       " '.',\n",
       " 'No',\n",
       " 'wonder',\n",
       " 'that',\n",
       " 'we',\n",
       " 'have',\n",
       " 'received',\n",
       " 'thousands',\n",
       " 'of',\n",
       " 'applications',\n",
       " ',',\n",
       " 'including',\n",
       " 'yours',\n",
       " '!',\n",
       " 'IPhone',\n",
       " 'XS',\n",
       " 'winner',\n",
       " 'this',\n",
       " 'week',\n",
       " 'is',\n",
       " '...',\n",
       " 'Agnieszka',\n",
       " 'Malankiewicz',\n",
       " 'Congratulations',\n",
       " ',',\n",
       " 'Agnieszka',\n",
       " ',',\n",
       " 'Receive',\n",
       " 'your',\n",
       " 'iPhone',\n",
       " 'XS',\n",
       " '!']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Agniesia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "#word stemming and lemmatisation\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_stemmer_and_lemmatizer(stemmer, lemmatizer, data, pos):\n",
    "    \"\"\"\n",
    "    Print the results of stemmind and lemmitization using the passed stemmer, lemmatizer, word and pos (part of speech)\n",
    "    \"\"\"\n",
    "    print(\"Stemmer:\", stemmer.stem(data))\n",
    "    print(\"Lemmatizer:\", lemmatizer.lemmatize(data, pos))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmer: receiv\n",
      "Lemmatizer: receive\n",
      "\n",
      "Stemmer: offer\n",
      "Lemmatizer: offer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "compare_stemmer_and_lemmatizer(stemmer, lemmatizer, data = \"received\", pos = wordnet.VERB)\n",
    "compare_stemmer_and_lemmatizer(stemmer, lemmatizer, data = \"offered\", pos = wordnet.VERB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Agniesia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "#stopwordsss\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "print(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['From', ':', 'Apple', 'Inc.', '-', 'Izolda', 'Jablonska', '<', 'reply', '@', 'unpogina.info', '>', 'Subject', ':', 'Nice', 'meet', ',', 'Agnieszka', 'Hello', 'Agnieszka', ',', 'Congratulations', 'recent', 'winners', 'Apple', 'smartphone', 'competition', '.', 'Apple', 'offered', 'chance', 'win', 'latest', 'iPhone', '-', 'one', 'popular', 'best', 'smartphones', 'moment', '.', 'No', 'wonder', 'received', 'thousands', 'applications', ',', 'including', '!', 'IPhone', 'XS', 'winner', 'week', '...', 'Agnieszka', 'Malankiewicz', 'Congratulations', ',', 'Agnieszka', ',', 'Receive', 'iPhone', 'XS', '!']\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "words = nltk.word_tokenize(data)\n",
    "without_stop_words = [word for word in words if not word in stop_words]\n",
    "print(without_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
